\chapter{Further Work}

\label{chap:further} 

In this last chapter we lay out some ideas for future work which were excluded from the project due to lack of time or because they were out-of-scope.

% We have evaluated some configurations and demonstrated that good tuning can lead to high returns. Next experiments should explore 
We have compared our models to Graham's criteria, but it would be interesting to add more expert's criteria to the benchmark, like Warren Buffett's, and evaluate them under different market regimes.

It would also be interesting to add more sklearn models to the mix and evaluating them. This could test the performance of \HPCsys under much larger experiments. We would also like to try time-series forecasting models like LSTM networks~\cite{lstm} and evaluate how to integrate this different kind of models into the evaluation pipeline.

The checkpointing system, although simple, was crucial to reusing data of the most massive executions whenever problems like time limit's or failure happened. Some great improvements to be done are: cache management options, like removing models once the execution is successful; and a naming system where the hash is computed from some fingerprint of the data thus removing the need of knowing all the parameters' values used to create the dataset.

The performance of the parallelization may become unbalanced if the model's training times vary too much between them. To mitigate this problem, it would be interesting to set a finer granularity and run the training of each session in a separate task. Then the resulting model of each training task should be fed to a trading/evaluation task. To this end, we have recently come across the distributed computing library~\cite{dislib} (dislib). This library is also built on top of PyCOMPSs and offers a grid search method out-of-the-box where each parametrization is evaluated in a separated task. The grid search could be used to, in each session, train all models and parametrizations and get the best model \textit{per trading session} instead of just the best at the end. On the one hand, this would delegate all the grid search handling to the dislib. On the other, this new structure would allow us to create a new model which automatically use the model reporting the best results with the training data of the session.

As a final note, we would like to see \HPCsys become a worth and usable open-source project for research. The first step would be to lay out a clearer specification and design a cleaner API so that users can plug in their custom data managers and models more easily. 
Anyone interested in contributing or using \HPCsys will be very welcome and appreciated.