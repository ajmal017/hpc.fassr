\chapter{Conclusions}
\label{chap:conclusions}

We have evaluated the parallelization performance of \HPCsys through the weak and strong scaling experiments. The results show that our system has linear speedup up to 1532 CPUs. However, workload imbalance caused by either too few models to train per core or by slow models might degrade the performance in some scenarios. We have also seen that the best results are reported by the slowest models showcasing the importance of having HPC-like computing resources to train them and find the best configurations in a reasonable amount of time.

For the trading performance, we set up three experiments: first, to compare Graham's criteria with classification models in stock screening with long positions; second, to compare classification and regression models with long/short positions; and finally, to evaluate regressors in stock ranking. The results of the first experiment show that all models have better average returns than Graham's criteria and all of them outperform S\&P 500 the index. The comparison in Experiment 2 showed that classifiers and regressors perform similarly and that SVM and random forests are the best in both tasks with the best SVM gaining a total revenue of around USD 1.8M. In the last experiment, we used regression information to build a stock ranking to then pick up the best and worst $k$ stocks. We found that using the regression information for stock ranking yields much higher revenues and with the best revenues obtained with 20 stocks in the portfolio. The best model is by a large margin the random forests which converts the initial USD 100K to 17.5 million.